{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-27T02:51:43.573575Z",
     "iopub.status.busy": "2022-09-27T02:51:43.572707Z",
     "iopub.status.idle": "2022-09-27T02:51:48.732713Z",
     "shell.execute_reply": "2022-09-27T02:51:48.731399Z",
     "shell.execute_reply.started": "2022-09-27T02:51:43.573488Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import numpy as np \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "#import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "\n",
    "from torchvision import models,transforms\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import brier_score_loss\n",
    "\n",
    "from scipy.stats import bernoulli, uniform\n",
    "\n",
    "from transformers import RobertaTokenizer, RobertaModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-27T02:51:48.742169Z",
     "iopub.status.busy": "2022-09-27T02:51:48.738777Z",
     "iopub.status.idle": "2022-09-27T02:51:48.867023Z",
     "shell.execute_reply": "2022-09-27T02:51:48.866047Z",
     "shell.execute_reply.started": "2022-09-27T02:51:48.742126Z"
    }
   },
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('../input/reddit-mental-health-data/Reddit Dataset/final_datasets/final_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-27T02:51:48.869432Z",
     "iopub.status.busy": "2022-09-27T02:51:48.868762Z",
     "iopub.status.idle": "2022-09-27T02:51:48.896960Z",
     "shell.execute_reply": "2022-09-27T02:51:48.896117Z",
     "shell.execute_reply.started": "2022-09-27T02:51:48.869394Z"
    }
   },
   "outputs": [],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-27T02:51:48.904855Z",
     "iopub.status.busy": "2022-09-27T02:51:48.901928Z",
     "iopub.status.idle": "2022-09-27T02:51:48.976802Z",
     "shell.execute_reply": "2022-09-27T02:51:48.975526Z",
     "shell.execute_reply.started": "2022-09-27T02:51:48.904817Z"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') #Use GPU if it's available or else use CPU.\n",
    "print(device)\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-27T02:51:48.979472Z",
     "iopub.status.busy": "2022-09-27T02:51:48.978745Z",
     "iopub.status.idle": "2022-09-27T02:51:52.917524Z",
     "shell.execute_reply": "2022-09-27T02:51:52.916504Z",
     "shell.execute_reply.started": "2022-09-27T02:51:48.979427Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from transformers import RobertaTokenizer\n",
    "\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "labels = {'adhd':0,\n",
    "          'anxiety':1,\n",
    "          'bipolar':2,\n",
    "          'depression':3,\n",
    "          'ptsd':4,\n",
    "          'none':5\n",
    "          }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-27T02:51:52.919604Z",
     "iopub.status.busy": "2022-09-27T02:51:52.919216Z",
     "iopub.status.idle": "2022-09-27T02:51:52.928715Z",
     "shell.execute_reply": "2022-09-27T02:51:52.927740Z",
     "shell.execute_reply.started": "2022-09-27T02:51:52.919567Z"
    }
   },
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, df, max_length, input_field):\n",
    "\n",
    "        self.labels = [torch.eye(6)[labels[label], :] for label in df['class_name']]\n",
    "        self.texts = [tokenizer(text, \n",
    "                               padding='max_length', max_length = max_length, truncation=True,\n",
    "                                return_tensors=\"pt\") for text in df[input_field]]\n",
    "\n",
    "    def classes(self):\n",
    "        return self.labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def get_batch_labels(self, idx):\n",
    "        # Fetch a batch of labels\n",
    "        return np.array(self.labels[idx])\n",
    "\n",
    "    def get_batch_texts(self, idx):\n",
    "        # Fetch a batch of inputs\n",
    "        return self.texts[idx]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        batch_texts = self.get_batch_texts(idx)\n",
    "        batch_y = self.get_batch_labels(idx)\n",
    "\n",
    "        return batch_texts, batch_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_kg_hide-input": false
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-27T02:51:52.931203Z",
     "iopub.status.busy": "2022-09-27T02:51:52.930456Z",
     "iopub.status.idle": "2022-09-27T02:51:52.942712Z",
     "shell.execute_reply": "2022-09-27T02:51:52.941752Z",
     "shell.execute_reply.started": "2022-09-27T02:51:52.931165Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from transformers import RobertaModel\n",
    "\n",
    "class RobertaClassifier(nn.Module):\n",
    "\n",
    "    def __init__(self, dropout=0.3):\n",
    "\n",
    "        super(RobertaClassifier, self).__init__()\n",
    "\n",
    "        self.roberta = RobertaModel.from_pretrained('roberta-base')\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear = nn.Linear(768, 6)\n",
    "        self.softmax = nn.Softmax()\n",
    "\n",
    "    def forward(self, input_id, mask):\n",
    "\n",
    "        output = self.roberta(input_ids= input_id, attention_mask=mask)\n",
    "        last_hidden_layer = output.last_hidden_state\n",
    "        del output\n",
    "        pooled_output = torch.mean(last_hidden_layer, dim = 1)\n",
    "        dropout_output = self.dropout(pooled_output)\n",
    "        linear_output = self.linear(dropout_output)\n",
    "        final_layer = self.softmax(linear_output)\n",
    "\n",
    "        return final_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-27T02:51:52.946693Z",
     "iopub.status.busy": "2022-09-27T02:51:52.945992Z",
     "iopub.status.idle": "2022-09-27T02:51:52.954821Z",
     "shell.execute_reply": "2022-09-27T02:51:52.953834Z",
     "shell.execute_reply.started": "2022-09-27T02:51:52.946653Z"
    }
   },
   "outputs": [],
   "source": [
    "def calc_bins(preds,labels_oneh):\n",
    "    # Assign each prediction to a bin\n",
    "    num_bins = 5\n",
    "    bins = torch.linspace(0.1, 1, num_bins)\n",
    "    #bins = bins.to(device)\n",
    "    #print(preds)\n",
    "    #print(bins)\n",
    "    binned = torch.bucketize(preds, bins)\n",
    "\n",
    "    # Save the accuracy, confidence and size of each bin\n",
    "    bin_accs = torch.zeros(num_bins)\n",
    "    bin_confs = torch.zeros(num_bins)\n",
    "    bin_sizes = torch.zeros(num_bins)\n",
    "\n",
    "    for bin in range(num_bins):\n",
    "        bin_sizes[bin] = len(preds[binned == bin])\n",
    "        if bin_sizes[bin] > 0:\n",
    "            bin_accs[bin] = (labels_oneh[binned==bin]).sum() / bin_sizes[bin]\n",
    "            bin_confs[bin] = (preds[binned==bin]).sum() / bin_sizes[bin]\n",
    "\n",
    "    return bins, binned, bin_accs, bin_confs, bin_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-27T02:51:52.958527Z",
     "iopub.status.busy": "2022-09-27T02:51:52.958254Z",
     "iopub.status.idle": "2022-09-27T02:51:52.969054Z",
     "shell.execute_reply": "2022-09-27T02:51:52.968029Z",
     "shell.execute_reply.started": "2022-09-27T02:51:52.958501Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_metrics(preds,labels):\n",
    "    ECE = 0\n",
    "    MCE = 0\n",
    "    bins, _, bin_accs, bin_confs, bin_sizes = calc_bins(preds,labels)\n",
    "\n",
    "    for i in range(len(bins)):\n",
    "        abs_conf_dif = abs(bin_accs[i] - bin_confs[i])\n",
    "        ECE += (bin_sizes[i] / sum(bin_sizes)) * abs_conf_dif\n",
    "        MCE = max(MCE, abs_conf_dif)\n",
    "\n",
    "    return ECE, MCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-27T02:51:52.975185Z",
     "iopub.status.busy": "2022-09-27T02:51:52.974773Z",
     "iopub.status.idle": "2022-09-27T02:51:52.989896Z",
     "shell.execute_reply": "2022-09-27T02:51:52.988678Z",
     "shell.execute_reply.started": "2022-09-27T02:51:52.975154Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_posts(model, df_test, max_length, input_field):\n",
    "    \n",
    "    test = Dataset(df_test, max_length, input_field)\n",
    "\n",
    "    test_dataloader = torch.utils.data.DataLoader(test, batch_size=16)\n",
    "\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "    if use_cuda:\n",
    "\n",
    "        model = model.cuda()\n",
    "\n",
    "    model.eval()\n",
    "    pred_lst = []\n",
    "    gt_lst = []\n",
    "    \n",
    "    total_acc_test = 0\n",
    "    total_loss_test = 0\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "\n",
    "        for test_input, test_label in test_dataloader:\n",
    "\n",
    "            test_label = test_label.to(device)\n",
    "            mask = test_input['attention_mask'].squeeze(1).to(device)\n",
    "            input_id = test_input['input_ids'].squeeze(1).to(device)\n",
    "\n",
    "            output = model(input_id, mask)\n",
    "            \n",
    "            batch_loss = criterion(output, test_label)\n",
    "            total_loss_test += batch_loss.item()\n",
    "\n",
    "            acc = (output.argmax(dim=1) == test_label.argmax(dim=1)).sum().item()\n",
    "            total_acc_test += acc\n",
    "            \n",
    "            output=output.detach().cpu().numpy()\n",
    "            pred_lst.append(output)\n",
    "            test_label = test_label.detach().cpu().numpy()\n",
    "            gt_lst.append(test_label)\n",
    "            \n",
    "        pred_lst=np.concatenate(pred_lst, axis=0)\n",
    "        gt_lst=np.concatenate(gt_lst, axis=0)\n",
    "        \n",
    "        ECE, MCE = get_metrics(torch.Tensor(pred_lst).cpu(),torch.Tensor(gt_lst).cpu())\n",
    "        \n",
    "        pred_lst2 = np.argmax(pred_lst, axis=1)\n",
    "        gt_lst2 = np.argmax(gt_lst, axis=1)\n",
    "        auc_lst=[]\n",
    "        for k in range(0,5):\n",
    "            tmp_gt=gt_lst[:, k]\n",
    "            tmp_pred=pred_lst[:,k]\n",
    "            try:\n",
    "                tmp_auc=roc_auc_score(tmp_gt, tmp_pred)\n",
    "            except ValueError:\n",
    "                print(\"error\")\n",
    "                tmp_auc=0\n",
    "            auc_lst.append(tmp_auc)\n",
    "\n",
    "        brier_score = np.mean(np.sum((pred_lst - gt_lst)**2, axis=1))\n",
    "        auc_lst=np.array(auc_lst)\n",
    "        auc=np.mean(auc_lst)\n",
    "        f1 = f1_score(gt_lst2, pred_lst2, average='weighted')\n",
    "        print(classification_report(gt_lst2, pred_lst2, labels=[0,1, 2, 3,4,5]))\n",
    "    \n",
    "        print(\n",
    "            f'Test Loss: {total_loss_test / len(test): .3f} \\\n",
    "            | Test Accuracy: {total_acc_test / len(df_test): .3f} \\\n",
    "            | Test AUC: {auc: .3f} \\\n",
    "            | Test f1 Score: {f1: .3f}\\\n",
    "            | Brier Score: {brier_score: .3f} \\\n",
    "            | Expected Calibration Score: {ECE: .3f} \\\n",
    "            | Maximum Calibration Score: {MCE: .3f} ')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating on posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-27T02:51:52.992603Z",
     "iopub.status.busy": "2022-09-27T02:51:52.992225Z",
     "iopub.status.idle": "2022-09-27T02:52:50.944809Z",
     "shell.execute_reply": "2022-09-27T02:52:50.943677Z",
     "shell.execute_reply.started": "2022-09-27T02:51:52.992522Z"
    }
   },
   "outputs": [],
   "source": [
    "model = RobertaClassifier()\n",
    "checkpoint = torch.load('../input/final-roberta-models/robertapost.pt')\n",
    "model.load_state_dict(checkpoint['model_state_dict'],strict=False)\n",
    "del checkpoint\n",
    "\n",
    "evaluate_posts(model, df_test, 512, 'post')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating on Titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-27T02:52:50.946896Z",
     "iopub.status.busy": "2022-09-27T02:52:50.946495Z",
     "iopub.status.idle": "2022-09-27T02:53:32.808639Z",
     "shell.execute_reply": "2022-09-27T02:53:32.807621Z",
     "shell.execute_reply.started": "2022-09-27T02:52:50.946857Z"
    }
   },
   "outputs": [],
   "source": [
    "model = RobertaClassifier()\n",
    "checkpoint = torch.load('../input/final-roberta-models/robertatitle.pt')\n",
    "model.load_state_dict(checkpoint['model_state_dict'],strict=False)\n",
    "del checkpoint\n",
    "\n",
    "evaluate_posts(model, df_test, 512, 'post')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating on Posts + Titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-27T02:53:32.810983Z",
     "iopub.status.busy": "2022-09-27T02:53:32.810420Z",
     "iopub.status.idle": "2022-09-27T02:54:14.125703Z",
     "shell.execute_reply": "2022-09-27T02:54:14.124690Z",
     "shell.execute_reply.started": "2022-09-27T02:53:32.810938Z"
    }
   },
   "outputs": [],
   "source": [
    "model = RobertaClassifier()\n",
    "checkpoint = torch.load('../input/final-roberta-models/robertatitle_post.pt')\n",
    "model.load_state_dict(checkpoint['model_state_dict'],strict=False)\n",
    "del checkpoint\n",
    "\n",
    "evaluate_posts(model, df_test, 512, 'title_post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
