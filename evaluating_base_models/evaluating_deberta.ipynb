{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-26T17:36:50.693098Z",
     "iopub.status.busy": "2022-09-26T17:36:50.692675Z",
     "iopub.status.idle": "2022-09-26T17:36:50.703397Z",
     "shell.execute_reply": "2022-09-26T17:36:50.702176Z",
     "shell.execute_reply.started": "2022-09-26T17:36:50.693065Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import numpy as np \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "#import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "\n",
    "from torchvision import models,transforms\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import brier_score_loss\n",
    "\n",
    "from scipy.stats import bernoulli, uniform\n",
    "\n",
    "from transformers import DebertaTokenizer, DebertaModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-26T17:36:50.707258Z",
     "iopub.status.busy": "2022-09-26T17:36:50.706952Z",
     "iopub.status.idle": "2022-09-26T17:36:51.105799Z",
     "shell.execute_reply": "2022-09-26T17:36:51.104776Z",
     "shell.execute_reply.started": "2022-09-26T17:36:50.707230Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train =  pd.read_csv(\"../input/reddit-mental-health-data/Reddit Dataset/final_datasets/final_train.csv\")\n",
    "df_val =  pd.read_csv(\"../input/reddit-mental-health-data/Reddit Dataset/final_datasets/final_val.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-26T17:36:51.107810Z",
     "iopub.status.busy": "2022-09-26T17:36:51.107418Z",
     "iopub.status.idle": "2022-09-26T17:36:51.148391Z",
     "shell.execute_reply": "2022-09-26T17:36:51.147444Z",
     "shell.execute_reply.started": "2022-09-26T17:36:51.107771Z"
    }
   },
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('../input/reddit-mental-health-data/Reddit Dataset/final_datasets/final_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-26T17:36:51.151310Z",
     "iopub.status.busy": "2022-09-26T17:36:51.150907Z",
     "iopub.status.idle": "2022-09-26T17:36:51.165141Z",
     "shell.execute_reply": "2022-09-26T17:36:51.164184Z",
     "shell.execute_reply.started": "2022-09-26T17:36:51.151272Z"
    }
   },
   "outputs": [],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-26T17:36:51.167299Z",
     "iopub.status.busy": "2022-09-26T17:36:51.166605Z",
     "iopub.status.idle": "2022-09-26T17:36:51.178596Z",
     "shell.execute_reply": "2022-09-26T17:36:51.177399Z",
     "shell.execute_reply.started": "2022-09-26T17:36:51.167262Z"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') #Use GPU if it's available or else use CPU.\n",
    "print(device)\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-26T17:36:51.180909Z",
     "iopub.status.busy": "2022-09-26T17:36:51.180448Z",
     "iopub.status.idle": "2022-09-26T17:36:51.894379Z",
     "shell.execute_reply": "2022-09-26T17:36:51.893392Z",
     "shell.execute_reply.started": "2022-09-26T17:36:51.180863Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from transformers import DebertaTokenizer\n",
    "\n",
    "tokenizer = DebertaTokenizer.from_pretrained('microsoft/deberta-base')\n",
    "labels = {'adhd':0,\n",
    "          'anxiety':1,\n",
    "          'bipolar':2,\n",
    "          'depression':3,\n",
    "          'ptsd':4,\n",
    "          'none':5\n",
    "          }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-26T17:36:51.896064Z",
     "iopub.status.busy": "2022-09-26T17:36:51.895697Z",
     "iopub.status.idle": "2022-09-26T17:36:51.906276Z",
     "shell.execute_reply": "2022-09-26T17:36:51.903833Z",
     "shell.execute_reply.started": "2022-09-26T17:36:51.896027Z"
    }
   },
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, df, max_length, input_field):\n",
    "\n",
    "        self.labels = [torch.eye(6)[labels[label], :] for label in df['class_name']]\n",
    "        self.texts = [tokenizer(text, \n",
    "                               padding='max_length', max_length = max_length, truncation=True,\n",
    "                                return_tensors=\"pt\") for text in df[input_field]]\n",
    "\n",
    "    def classes(self):\n",
    "        return self.labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def get_batch_labels(self, idx):\n",
    "        # Fetch a batch of labels\n",
    "        return np.array(self.labels[idx])\n",
    "\n",
    "    def get_batch_texts(self, idx):\n",
    "        # Fetch a batch of inputs\n",
    "        return self.texts[idx]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        batch_texts = self.get_batch_texts(idx)\n",
    "        batch_y = self.get_batch_labels(idx)\n",
    "\n",
    "        return batch_texts, batch_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_kg_hide-input": false
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-26T17:36:51.909105Z",
     "iopub.status.busy": "2022-09-26T17:36:51.907943Z",
     "iopub.status.idle": "2022-09-26T17:36:51.918247Z",
     "shell.execute_reply": "2022-09-26T17:36:51.917176Z",
     "shell.execute_reply.started": "2022-09-26T17:36:51.909055Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from transformers import DebertaModel\n",
    "\n",
    "class DebertaClassifier(nn.Module):\n",
    "\n",
    "    def __init__(self, dropout=0.3):\n",
    "\n",
    "        super(DebertaClassifier, self).__init__()\n",
    "\n",
    "        self.deberta = DebertaModel.from_pretrained('microsoft/deberta-base')\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear = nn.Linear(768, 6)\n",
    "        self.relu = nn.Softmax()\n",
    "\n",
    "    def forward(self, input_id, mask):\n",
    "\n",
    "        output = self.deberta(input_ids= input_id, attention_mask=mask)\n",
    "        last_hidden_layer = output.last_hidden_state\n",
    "        del output\n",
    "        pooled_output = torch.mean(last_hidden_layer, dim = 1)\n",
    "        dropout_output = self.dropout(pooled_output)\n",
    "        linear_output = self.linear(dropout_output)\n",
    "        final_layer = self.relu(linear_output)\n",
    "\n",
    "        return final_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-26T17:36:51.922565Z",
     "iopub.status.busy": "2022-09-26T17:36:51.922153Z",
     "iopub.status.idle": "2022-09-26T17:36:51.933231Z",
     "shell.execute_reply": "2022-09-26T17:36:51.932260Z",
     "shell.execute_reply.started": "2022-09-26T17:36:51.922536Z"
    }
   },
   "outputs": [],
   "source": [
    "def calc_bins(preds,labels_oneh):\n",
    "    # Assign each prediction to a bin\n",
    "    num_bins = 5\n",
    "    bins = torch.linspace(0.1, 1, num_bins)\n",
    "    #bins = bins.to(device)\n",
    "    #print(preds)\n",
    "    #print(bins)\n",
    "    binned = torch.bucketize(preds, bins)\n",
    "\n",
    "    # Save the accuracy, confidence and size of each bin\n",
    "    bin_accs = torch.zeros(num_bins)\n",
    "    bin_confs = torch.zeros(num_bins)\n",
    "    bin_sizes = torch.zeros(num_bins)\n",
    "\n",
    "    for bin in range(num_bins):\n",
    "        bin_sizes[bin] = len(preds[binned == bin])\n",
    "        if bin_sizes[bin] > 0:\n",
    "            bin_accs[bin] = (labels_oneh[binned==bin]).sum() / bin_sizes[bin]\n",
    "            bin_confs[bin] = (preds[binned==bin]).sum() / bin_sizes[bin]\n",
    "\n",
    "    return bins, binned, bin_accs, bin_confs, bin_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-26T17:36:51.935316Z",
     "iopub.status.busy": "2022-09-26T17:36:51.934862Z",
     "iopub.status.idle": "2022-09-26T17:36:51.943214Z",
     "shell.execute_reply": "2022-09-26T17:36:51.942231Z",
     "shell.execute_reply.started": "2022-09-26T17:36:51.935279Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_metrics(preds,labels):\n",
    "    ECE = 0\n",
    "    MCE = 0\n",
    "    bins, _, bin_accs, bin_confs, bin_sizes = calc_bins(preds,labels)\n",
    "\n",
    "    for i in range(len(bins)):\n",
    "        abs_conf_dif = abs(bin_accs[i] - bin_confs[i])\n",
    "        ECE += (bin_sizes[i] / sum(bin_sizes)) * abs_conf_dif\n",
    "        MCE = max(MCE, abs_conf_dif)\n",
    "\n",
    "    return ECE, MCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-26T17:36:51.945415Z",
     "iopub.status.busy": "2022-09-26T17:36:51.945045Z",
     "iopub.status.idle": "2022-09-26T17:36:51.962356Z",
     "shell.execute_reply": "2022-09-26T17:36:51.961488Z",
     "shell.execute_reply.started": "2022-09-26T17:36:51.945379Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_posts(model, df_test, max_length, input_field):\n",
    "    \n",
    "    test = Dataset(df_test, max_length, input_field)\n",
    "\n",
    "    test_dataloader = torch.utils.data.DataLoader(test, batch_size=16)\n",
    "\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "    if use_cuda:\n",
    "\n",
    "        model = model.cuda()\n",
    "\n",
    "    model.eval()\n",
    "    pred_lst = []\n",
    "    gt_lst = []\n",
    "    \n",
    "    total_acc_test = 0\n",
    "    total_loss_test = 0\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "\n",
    "        for test_input, test_label in test_dataloader:\n",
    "\n",
    "            test_label = test_label.squeeze(1).to(device)\n",
    "            mask = test_input['attention_mask'].squeeze(1).to(device)\n",
    "            input_id = test_input['input_ids'].squeeze(1).to(device)\n",
    "\n",
    "            output = model(input_id, mask)\n",
    "            \n",
    "            batch_loss = criterion(output, test_label)\n",
    "            total_loss_test += batch_loss.item()\n",
    "\n",
    "            acc = (output.argmax(dim=1) == test_label.argmax(dim=1)).sum().item()\n",
    "            total_acc_test += acc\n",
    "            \n",
    "            output=output.detach().cpu().numpy()\n",
    "            pred_lst.append(output)\n",
    "            test_label = test_label.detach().cpu().numpy()\n",
    "            gt_lst.append(test_label)\n",
    "            \n",
    "        pred_lst=np.concatenate(pred_lst, axis=0)\n",
    "        gt_lst=np.concatenate(gt_lst, axis=0)\n",
    "        \n",
    "        ECE, MCE = get_metrics(torch.Tensor(pred_lst).cpu(),torch.Tensor(gt_lst).cpu())\n",
    "        \n",
    "        pred_lst2 = np.argmax(pred_lst, axis=1)\n",
    "        gt_lst2 = np.argmax(gt_lst, axis=1)\n",
    "        auc_lst=[]\n",
    "        for k in range(0,5):\n",
    "            tmp_gt=gt_lst[:, k]\n",
    "            tmp_pred=pred_lst[:,k]\n",
    "            try:\n",
    "                tmp_auc=roc_auc_score(tmp_gt, tmp_pred)\n",
    "            except ValueError:\n",
    "                print(\"error\")\n",
    "                tmp_auc=0\n",
    "            auc_lst.append(tmp_auc)\n",
    "\n",
    "        brier_score = np.mean(np.sum((pred_lst - gt_lst)**2, axis=1))\n",
    "        auc_lst=np.array(auc_lst)\n",
    "        auc=np.mean(auc_lst)\n",
    "        f1 = f1_score(gt_lst2, pred_lst2, average='weighted')\n",
    "        print(classification_report(gt_lst2, pred_lst2, labels=[0,1, 2, 3,4,5]))\n",
    "    \n",
    "        print(\n",
    "            f'Test Loss: {total_loss_test / len(test): .3f} \\\n",
    "            | Test Accuracy: {total_acc_test / len(df_test): .3f} \\\n",
    "            | Test AUC: {auc: .3f} \\\n",
    "            | Test f1 Score: {f1: .3f}\\\n",
    "            | Brier Score: {brier_score: .3f} \\\n",
    "            | Expected Calibration Score: {ECE: .3f} \\\n",
    "            | Maximum Calibration Score: {MCE: .3f} ')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating on posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-26T17:36:51.964461Z",
     "iopub.status.busy": "2022-09-26T17:36:51.963673Z",
     "iopub.status.idle": "2022-09-26T17:37:39.665704Z",
     "shell.execute_reply": "2022-09-26T17:37:39.663665Z",
     "shell.execute_reply.started": "2022-09-26T17:36:51.964421Z"
    }
   },
   "outputs": [],
   "source": [
    "model = DebertaClassifier()\n",
    "checkpoint = torch.load('../input/final-deberta-models/debertapost.pt')\n",
    "model.load_state_dict(checkpoint['model_state_dict'],strict=False)\n",
    "del checkpoint\n",
    "\n",
    "evaluate_posts(model, df_test, 512, 'post')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating on Titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-26T17:37:39.668591Z",
     "iopub.status.busy": "2022-09-26T17:37:39.667542Z",
     "iopub.status.idle": "2022-09-26T17:38:26.334076Z",
     "shell.execute_reply": "2022-09-26T17:38:26.333020Z",
     "shell.execute_reply.started": "2022-09-26T17:37:39.668550Z"
    }
   },
   "outputs": [],
   "source": [
    "model = DebertaClassifier()\n",
    "checkpoint = torch.load('../input/final-deberta-models/debertatitle.pt')\n",
    "model.load_state_dict(checkpoint['model_state_dict'],strict=False)\n",
    "del checkpoint\n",
    "\n",
    "evaluate_posts(model, df_test, 512, 'post')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating on Posts + Titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-26T17:38:26.353948Z",
     "iopub.status.busy": "2022-09-26T17:38:26.353675Z",
     "iopub.status.idle": "2022-09-26T17:39:43.955570Z",
     "shell.execute_reply": "2022-09-26T17:39:43.953305Z",
     "shell.execute_reply.started": "2022-09-26T17:38:26.353916Z"
    }
   },
   "outputs": [],
   "source": [
    "model = DebertaClassifier()\n",
    "checkpoint = torch.load('../input/final-deberta-models/debertatittle_post.pt')\n",
    "model.load_state_dict(checkpoint['model_state_dict'],strict=False)\n",
    "del checkpoint\n",
    "\n",
    "\n",
    "evaluate_posts(model, df_test, 512, 'title_post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
