{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-27T03:00:14.492220Z",
     "iopub.status.busy": "2022-09-27T03:00:14.490836Z",
     "iopub.status.idle": "2022-09-27T03:00:14.504305Z",
     "shell.execute_reply": "2022-09-27T03:00:14.501723Z",
     "shell.execute_reply.started": "2022-09-27T03:00:14.492174Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import numpy as np \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "#import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "\n",
    "from torchvision import models,transforms\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import brier_score_loss\n",
    "\n",
    "from scipy.stats import bernoulli, uniform\n",
    "\n",
    "from transformers import AlbertTokenizer, AlbertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-27T03:00:14.507383Z",
     "iopub.status.busy": "2022-09-27T03:00:14.506746Z",
     "iopub.status.idle": "2022-09-27T03:00:14.645332Z",
     "shell.execute_reply": "2022-09-27T03:00:14.644203Z",
     "shell.execute_reply.started": "2022-09-27T03:00:14.507347Z"
    }
   },
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('../input/reddit-mental-health-data/Reddit Dataset/final_datasets/final_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-27T03:00:14.648956Z",
     "iopub.status.busy": "2022-09-27T03:00:14.648297Z",
     "iopub.status.idle": "2022-09-27T03:00:14.674144Z",
     "shell.execute_reply": "2022-09-27T03:00:14.673239Z",
     "shell.execute_reply.started": "2022-09-27T03:00:14.648918Z"
    }
   },
   "outputs": [],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-27T03:00:14.680976Z",
     "iopub.status.busy": "2022-09-27T03:00:14.678603Z",
     "iopub.status.idle": "2022-09-27T03:00:14.756228Z",
     "shell.execute_reply": "2022-09-27T03:00:14.755160Z",
     "shell.execute_reply.started": "2022-09-27T03:00:14.680939Z"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') #Use GPU if it's available or else use CPU.\n",
    "print(device)\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-27T03:00:14.761437Z",
     "iopub.status.busy": "2022-09-27T03:00:14.760793Z",
     "iopub.status.idle": "2022-09-27T03:00:15.726044Z",
     "shell.execute_reply": "2022-09-27T03:00:15.724974Z",
     "shell.execute_reply.started": "2022-09-27T03:00:14.761398Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from transformers import AlbertTokenizer\n",
    "\n",
    "tokenizer = AlbertTokenizer.from_pretrained('albert-base-v2')\n",
    "labels = {'adhd':0,\n",
    "          'anxiety':1,\n",
    "          'bipolar':2,\n",
    "          'depression':3,\n",
    "          'ptsd':4,\n",
    "          'none':5\n",
    "          }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-27T03:00:15.728029Z",
     "iopub.status.busy": "2022-09-27T03:00:15.727662Z",
     "iopub.status.idle": "2022-09-27T03:00:15.736598Z",
     "shell.execute_reply": "2022-09-27T03:00:15.735487Z",
     "shell.execute_reply.started": "2022-09-27T03:00:15.727993Z"
    }
   },
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, df, max_length, input_field):\n",
    "\n",
    "        self.labels = [torch.eye(6)[labels[label], :] for label in df['class_name']]\n",
    "        self.texts = [tokenizer(text, \n",
    "                               padding='max_length', max_length = max_length, truncation=True,\n",
    "                                return_tensors=\"pt\") for text in df[input_field]]\n",
    "\n",
    "    def classes(self):\n",
    "        return self.labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def get_batch_labels(self, idx):\n",
    "        # Fetch a batch of labels\n",
    "        return np.array(self.labels[idx])\n",
    "\n",
    "    def get_batch_texts(self, idx):\n",
    "        # Fetch a batch of inputs\n",
    "        return self.texts[idx]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        batch_texts = self.get_batch_texts(idx)\n",
    "        batch_y = self.get_batch_labels(idx)\n",
    "\n",
    "        return batch_texts, batch_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_kg_hide-input": false
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-27T03:03:21.267449Z",
     "iopub.status.busy": "2022-09-27T03:03:21.267011Z",
     "iopub.status.idle": "2022-09-27T03:03:21.277764Z",
     "shell.execute_reply": "2022-09-27T03:03:21.276668Z",
     "shell.execute_reply.started": "2022-09-27T03:03:21.267401Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from transformers import AlbertModel\n",
    "\n",
    "class AlbertClassifier(nn.Module):\n",
    "\n",
    "    def __init__(self, dropout=0.3):\n",
    "\n",
    "        super(AlbertClassifier, self).__init__()\n",
    "\n",
    "        self.albert = AlbertModel.from_pretrained('albert-base-v2')\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear = nn.Linear(768, 6)\n",
    "        self.relu = nn.Softmax()\n",
    "\n",
    "    def forward(self, input_id, mask):\n",
    "\n",
    "        output = self.albert(input_ids= input_id, attention_mask=mask)\n",
    "        last_hidden_layer = output.last_hidden_state\n",
    "        del output\n",
    "        pooled_output = torch.mean(last_hidden_layer, dim = 1)\n",
    "        dropout_output = self.dropout(pooled_output)\n",
    "        linear_output = self.linear(dropout_output)\n",
    "        final_layer = self.relu(linear_output)\n",
    "\n",
    "        return final_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-27T03:03:21.716976Z",
     "iopub.status.busy": "2022-09-27T03:03:21.716574Z",
     "iopub.status.idle": "2022-09-27T03:03:21.726801Z",
     "shell.execute_reply": "2022-09-27T03:03:21.725604Z",
     "shell.execute_reply.started": "2022-09-27T03:03:21.716942Z"
    }
   },
   "outputs": [],
   "source": [
    "def calc_bins(preds,labels_oneh):\n",
    "    # Assign each prediction to a bin\n",
    "    num_bins = 5\n",
    "    bins = torch.linspace(0.1, 1, num_bins)\n",
    "    #bins = bins.to(device)\n",
    "    #print(preds)\n",
    "    #print(bins)\n",
    "    binned = torch.bucketize(preds, bins)\n",
    "\n",
    "    # Save the accuracy, confidence and size of each bin\n",
    "    bin_accs = torch.zeros(num_bins)\n",
    "    bin_confs = torch.zeros(num_bins)\n",
    "    bin_sizes = torch.zeros(num_bins)\n",
    "\n",
    "    for bin in range(num_bins):\n",
    "        bin_sizes[bin] = len(preds[binned == bin])\n",
    "        if bin_sizes[bin] > 0:\n",
    "            bin_accs[bin] = (labels_oneh[binned==bin]).sum() / bin_sizes[bin]\n",
    "            bin_confs[bin] = (preds[binned==bin]).sum() / bin_sizes[bin]\n",
    "\n",
    "    return bins, binned, bin_accs, bin_confs, bin_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-27T03:03:21.888468Z",
     "iopub.status.busy": "2022-09-27T03:03:21.888126Z",
     "iopub.status.idle": "2022-09-27T03:03:21.895017Z",
     "shell.execute_reply": "2022-09-27T03:03:21.893821Z",
     "shell.execute_reply.started": "2022-09-27T03:03:21.888438Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_metrics(preds,labels):\n",
    "    ECE = 0\n",
    "    MCE = 0\n",
    "    bins, _, bin_accs, bin_confs, bin_sizes = calc_bins(preds,labels)\n",
    "\n",
    "    for i in range(len(bins)):\n",
    "        abs_conf_dif = abs(bin_accs[i] - bin_confs[i])\n",
    "        ECE += (bin_sizes[i] / sum(bin_sizes)) * abs_conf_dif\n",
    "        MCE = max(MCE, abs_conf_dif)\n",
    "\n",
    "    return ECE, MCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-27T03:03:22.089834Z",
     "iopub.status.busy": "2022-09-27T03:03:22.088984Z",
     "iopub.status.idle": "2022-09-27T03:03:22.103973Z",
     "shell.execute_reply": "2022-09-27T03:03:22.102983Z",
     "shell.execute_reply.started": "2022-09-27T03:03:22.089788Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_posts(model, df_test, max_length, input_field):\n",
    "    \n",
    "    test = Dataset(df_test, max_length, input_field)\n",
    "\n",
    "    test_dataloader = torch.utils.data.DataLoader(test, batch_size=16)\n",
    "\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "    if use_cuda:\n",
    "\n",
    "        model = model.cuda()\n",
    "\n",
    "    model.eval()\n",
    "    pred_lst = []\n",
    "    gt_lst = []\n",
    "    \n",
    "    total_acc_test = 0\n",
    "    total_loss_test = 0\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "\n",
    "        for test_input, test_label in test_dataloader:\n",
    "\n",
    "            test_label = test_label.to(device)\n",
    "            mask = test_input['attention_mask'].squeeze(1).to(device)\n",
    "            input_id = test_input['input_ids'].squeeze(1).to(device)\n",
    "\n",
    "            output = model(input_id, mask)\n",
    "            \n",
    "            batch_loss = criterion(output, test_label)\n",
    "            total_loss_test += batch_loss.item()\n",
    "\n",
    "            acc = (output.argmax(dim=1) == test_label.argmax(dim=1)).sum().item()\n",
    "            total_acc_test += acc\n",
    "            \n",
    "            output=output.detach().cpu().numpy()\n",
    "            pred_lst.append(output)\n",
    "            test_label = test_label.detach().cpu().numpy()\n",
    "            gt_lst.append(test_label)\n",
    "            \n",
    "        pred_lst=np.concatenate(pred_lst, axis=0)\n",
    "        gt_lst=np.concatenate(gt_lst, axis=0)\n",
    "        \n",
    "        ECE, MCE = get_metrics(torch.Tensor(pred_lst).cpu(),torch.Tensor(gt_lst).cpu())\n",
    "        \n",
    "        pred_lst2 = np.argmax(pred_lst, axis=1)\n",
    "        gt_lst2 = np.argmax(gt_lst, axis=1)\n",
    "        auc_lst=[]\n",
    "        for k in range(0,5):\n",
    "            tmp_gt=gt_lst[:, k]\n",
    "            tmp_pred=pred_lst[:,k]\n",
    "            try:\n",
    "                tmp_auc=roc_auc_score(tmp_gt, tmp_pred)\n",
    "            except ValueError:\n",
    "                print(\"error\")\n",
    "                tmp_auc=0\n",
    "            auc_lst.append(tmp_auc)\n",
    "\n",
    "        brier_score = np.mean(np.sum((pred_lst - gt_lst)**2, axis=1))\n",
    "        auc_lst=np.array(auc_lst)\n",
    "        auc=np.mean(auc_lst)\n",
    "        f1 = f1_score(gt_lst2, pred_lst2, average='weighted')\n",
    "        print(classification_report(gt_lst2, pred_lst2, labels=[0,1, 2, 3,4,5]))\n",
    "    \n",
    "        print(\n",
    "            f'Test Loss: {total_loss_test / len(test): .3f} \\\n",
    "            | Test Accuracy: {total_acc_test / len(df_test): .3f} \\\n",
    "            | Test AUC: {auc: .3f} \\\n",
    "            | Test f1 Score: {f1: .3f}\\\n",
    "            | Brier Score: {brier_score: .3f} \\\n",
    "            | Expected Calibration Score: {ECE: .3f} \\\n",
    "            | Maximum Calibration Score: {MCE: .3f} ')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating on posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-27T03:03:22.418200Z",
     "iopub.status.busy": "2022-09-27T03:03:22.417834Z",
     "iopub.status.idle": "2022-09-27T03:03:22.783071Z",
     "shell.execute_reply": "2022-09-27T03:03:22.781476Z",
     "shell.execute_reply.started": "2022-09-27T03:03:22.418170Z"
    }
   },
   "outputs": [],
   "source": [
    "model = AlbertClassifier()\n",
    "checkpoint = torch.load('../input/final-albert-models/albertpost.pt')\n",
    "model.load_state_dict(checkpoint['model_state_dict'],strict=False)\n",
    "del checkpoint\n",
    "\n",
    "evaluate_posts(model, df_test, 512, 'post')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating on Titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-27T03:03:24.019178Z",
     "iopub.status.busy": "2022-09-27T03:03:24.018457Z",
     "iopub.status.idle": "2022-09-27T03:03:24.391672Z",
     "shell.execute_reply": "2022-09-27T03:03:24.390468Z",
     "shell.execute_reply.started": "2022-09-27T03:03:24.019141Z"
    }
   },
   "outputs": [],
   "source": [
    "model = AlbertClassifier()\n",
    "checkpoint = torch.load('../input/final-albert-models/alberttitle.pt')\n",
    "model.load_state_dict(checkpoint['model_state_dict'],strict=False)\n",
    "del checkpoint\n",
    "\n",
    "evaluate_posts(model, df_test, 512, 'title')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating on Posts + Titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-27T03:03:26.460698Z",
     "iopub.status.busy": "2022-09-27T03:03:26.459808Z",
     "iopub.status.idle": "2022-09-27T03:03:58.852454Z",
     "shell.execute_reply": "2022-09-27T03:03:58.851325Z",
     "shell.execute_reply.started": "2022-09-27T03:03:26.460651Z"
    }
   },
   "outputs": [],
   "source": [
    "model = AlbertClassifier()\n",
    "checkpoint = torch.load('../input/final-albert-models/alberttitle_post.pt')\n",
    "model.load_state_dict(checkpoint['model_state_dict'],strict=False)\n",
    "del checkpoint\n",
    "\n",
    "evaluate_posts(model, df_test, 512, 'title_post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
